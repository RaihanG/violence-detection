{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import sklearn\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['violent','non_violent']\n",
    "# path = \"C:/Users/NBH/Desktop/raw/dataset/train/10_FPS/30x30/\"\n",
    "# for label in labels:\n",
    "#     vector=[]\n",
    "\n",
    "#     images = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "#     for image in images:\n",
    "#         img=cv2.imread(image,0)\n",
    "#         #print(img)\n",
    "#         vector.append(img)\n",
    "#     vector = np.asarray(vector)\n",
    "#     np.save(label + '.npy', vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/train/'+labels[0] + '.npy')\n",
    "y_train = np.zeros(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15258, 30, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(labels[1:]):\n",
    "    x = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/train/'+label + '.npy')\n",
    "    X_train = np.vstack((X_train, x))\n",
    "    y_train = np.append(y_train, np.full(x.shape[0], fill_value= (i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26745, 30, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:/Users/NBH/Desktop/raw/dataset/test/10_FPS/30x30/\"\n",
    "# for label in labels:\n",
    "#     vector=[]\n",
    "\n",
    "#     images = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "#     for image in images:\n",
    "#         img=cv2.imread(image,0)\n",
    "# #         print(img)\n",
    "#         vector.append(img)\n",
    "#     vector = np.asarray(vector)\n",
    "#     np.save(label + '.npy', vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(X_train.shape[0],30,30,1)\n",
    "# X_test = X_test.reshape(X_test.shape[0],30,30,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/test/'+labels[0] + '.npy')\n",
    "y_test = np.zeros(X_test.shape[0])\n",
    "\n",
    "for i, label in enumerate(labels[1:]):\n",
    "    x = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/test/'+label + '.npy')\n",
    "    X_test = np.vstack((X_test, x))\n",
    "    y_test = np.append(y_test, np.full(x.shape[0], fill_value= (i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3924, 30, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 30, 30)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 30, 1)             91        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 15, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 15, 1)             4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 15, 1)             4         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 15, 100)           40800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 15, 100)           400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               150100    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 196,500\n",
      "Trainable params: 196,298\n",
      "Non-trainable params: 202\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "inp = Input((30,30))\n",
    "\n",
    "layer = Conv1D(1, 3, activation='relu', padding='same')(inp)\n",
    "layer = MaxPooling1D(2) (layer)\n",
    "layer = Conv1D(1, 3, activation='relu', padding='same')(layer)\n",
    "# layer = Conv1D(256, 3, activation='relu', padding='same')(layer)\n",
    "# layer = add([layer,inp])\n",
    "\n",
    "# layer = Activation('relu') (layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = LSTM(100, return_sequences=True, kernel_regularizer=regularizers.l2(0.01))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "#layer = Flatten() (layer)\n",
    "# layer = Dropout(0.5)(layer)\n",
    "layer = Flatten() (layer)\n",
    "# layer = Dense(100, activation='relu')(layer)\n",
    "layer = Dense(100, activation='relu')(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(50, activation='relu')(layer)\n",
    "out = Dense(1, activation='sigmoid')(layer)\n",
    "model = Model(input = inp, output = out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26745 samples, validate on 3924 samples\n",
      "Epoch 1/100\n",
      "26745/26745 [==============================] - 8s 313us/step - loss: 0.6731 - acc: 0.5942 - val_loss: 0.7382 - val_acc: 0.5336\n",
      "Epoch 2/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.6303 - acc: 0.6167 - val_loss: 0.7948 - val_acc: 0.5905\n",
      "Epoch 3/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.6070 - acc: 0.6334 - val_loss: 0.7377 - val_acc: 0.6251\n",
      "Epoch 4/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.5929 - acc: 0.6457 - val_loss: 0.7803 - val_acc: 0.5604\n",
      "Epoch 5/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.5805 - acc: 0.6645 - val_loss: 0.7081 - val_acc: 0.6353\n",
      "Epoch 6/100\n",
      "26745/26745 [==============================] - 6s 216us/step - loss: 0.5696 - acc: 0.6755 - val_loss: 0.6299 - val_acc: 0.6468\n",
      "Epoch 7/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.5585 - acc: 0.6893 - val_loss: 0.6112 - val_acc: 0.6544\n",
      "Epoch 8/100\n",
      "26745/26745 [==============================] - 6s 213us/step - loss: 0.5463 - acc: 0.7014 - val_loss: 0.6325 - val_acc: 0.6320\n",
      "Epoch 9/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.5380 - acc: 0.7097 - val_loss: 0.6080 - val_acc: 0.6414\n",
      "Epoch 10/100\n",
      "26745/26745 [==============================] - 6s 213us/step - loss: 0.5282 - acc: 0.7211 - val_loss: 0.6204 - val_acc: 0.6381\n",
      "Epoch 11/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.5225 - acc: 0.7258 - val_loss: 0.5965 - val_acc: 0.6560\n",
      "Epoch 12/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.5171 - acc: 0.7308 - val_loss: 0.6228 - val_acc: 0.6419\n",
      "Epoch 13/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.5099 - acc: 0.7360 - val_loss: 0.6227 - val_acc: 0.6455\n",
      "Epoch 14/100\n",
      "26745/26745 [==============================] - 6s 219us/step - loss: 0.5034 - acc: 0.7402 - val_loss: 0.6100 - val_acc: 0.6374\n",
      "Epoch 15/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.4986 - acc: 0.7432 - val_loss: 0.6031 - val_acc: 0.6506\n",
      "Epoch 16/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.4948 - acc: 0.7468 - val_loss: 0.6193 - val_acc: 0.6417\n",
      "Epoch 17/100\n",
      "26745/26745 [==============================] - 6s 216us/step - loss: 0.4892 - acc: 0.7513 - val_loss: 0.5831 - val_acc: 0.6598\n",
      "Epoch 18/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.4852 - acc: 0.7525 - val_loss: 0.5827 - val_acc: 0.6728\n",
      "Epoch 19/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.4843 - acc: 0.7561 - val_loss: 0.6148 - val_acc: 0.6391\n",
      "Epoch 20/100\n",
      "26745/26745 [==============================] - 6s 218us/step - loss: 0.4753 - acc: 0.7610 - val_loss: 0.6197 - val_acc: 0.6374\n",
      "Epoch 21/100\n",
      "26745/26745 [==============================] - 6s 213us/step - loss: 0.4733 - acc: 0.7628 - val_loss: 0.5995 - val_acc: 0.6511\n",
      "Epoch 22/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.4704 - acc: 0.7657 - val_loss: 0.5998 - val_acc: 0.6524\n",
      "Epoch 23/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.4619 - acc: 0.7711 - val_loss: 0.6109 - val_acc: 0.6346\n",
      "Epoch 24/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.4625 - acc: 0.7692 - val_loss: 0.5966 - val_acc: 0.6672\n",
      "Epoch 25/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.4550 - acc: 0.7759 - val_loss: 0.5877 - val_acc: 0.6562\n",
      "Epoch 26/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.4505 - acc: 0.7775 - val_loss: 0.6302 - val_acc: 0.6381\n",
      "Epoch 27/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.4448 - acc: 0.7827 - val_loss: 0.5864 - val_acc: 0.6695\n",
      "Epoch 28/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.4407 - acc: 0.7836 - val_loss: 0.7052 - val_acc: 0.6078\n",
      "Epoch 29/100\n",
      "26745/26745 [==============================] - 6s 216us/step - loss: 0.4387 - acc: 0.7872 - val_loss: 0.6125 - val_acc: 0.6338\n",
      "Epoch 30/100\n",
      "26745/26745 [==============================] - 6s 213us/step - loss: 0.4344 - acc: 0.7884 - val_loss: 0.6479 - val_acc: 0.6580\n",
      "Epoch 31/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.4314 - acc: 0.7938 - val_loss: 0.5952 - val_acc: 0.6636\n",
      "Epoch 32/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.4262 - acc: 0.7974 - val_loss: 0.6895 - val_acc: 0.6463\n",
      "Epoch 33/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.4219 - acc: 0.7965 - val_loss: 0.6390 - val_acc: 0.6351\n",
      "Epoch 34/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.4192 - acc: 0.7988 - val_loss: 0.6258 - val_acc: 0.6585\n",
      "Epoch 35/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.4180 - acc: 0.8014 - val_loss: 0.6130 - val_acc: 0.6649\n",
      "Epoch 36/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.4110 - acc: 0.8053 - val_loss: 0.6553 - val_acc: 0.6695\n",
      "Epoch 37/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.4063 - acc: 0.8072 - val_loss: 0.6306 - val_acc: 0.6804\n",
      "Epoch 38/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.4059 - acc: 0.8050 - val_loss: 0.5810 - val_acc: 0.6922\n",
      "Epoch 39/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.3997 - acc: 0.8122 - val_loss: 0.6485 - val_acc: 0.6687\n",
      "Epoch 40/100\n",
      "26745/26745 [==============================] - 6s 219us/step - loss: 0.3969 - acc: 0.8141 - val_loss: 0.6246 - val_acc: 0.6707\n",
      "Epoch 41/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.3911 - acc: 0.8142 - val_loss: 0.6200 - val_acc: 0.6809\n",
      "Epoch 42/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.3877 - acc: 0.8178 - val_loss: 0.6613 - val_acc: 0.6493\n",
      "Epoch 43/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3892 - acc: 0.8163 - val_loss: 0.6797 - val_acc: 0.6292\n",
      "Epoch 44/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.3821 - acc: 0.8218 - val_loss: 0.6340 - val_acc: 0.6674\n",
      "Epoch 45/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3781 - acc: 0.8206 - val_loss: 0.5847 - val_acc: 0.6878\n",
      "Epoch 46/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.3775 - acc: 0.8248 - val_loss: 0.5924 - val_acc: 0.6919\n",
      "Epoch 47/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.3744 - acc: 0.8228 - val_loss: 0.6362 - val_acc: 0.6659\n",
      "Epoch 48/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.3721 - acc: 0.8276 - val_loss: 0.6067 - val_acc: 0.6618\n",
      "Epoch 49/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.3688 - acc: 0.8266 - val_loss: 0.5931 - val_acc: 0.6735\n",
      "Epoch 50/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.3671 - acc: 0.8274 - val_loss: 0.6316 - val_acc: 0.6483\n",
      "Epoch 51/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.3660 - acc: 0.8284 - val_loss: 0.5741 - val_acc: 0.6781\n",
      "Epoch 52/100\n",
      "26745/26745 [==============================] - 6s 213us/step - loss: 0.3600 - acc: 0.8335 - val_loss: 0.6157 - val_acc: 0.6669\n",
      "Epoch 53/100\n",
      "26745/26745 [==============================] - 6s 216us/step - loss: 0.3567 - acc: 0.8338 - val_loss: 0.5768 - val_acc: 0.6776\n",
      "Epoch 54/100\n",
      "26745/26745 [==============================] - 6s 229us/step - loss: 0.3531 - acc: 0.8357 - val_loss: 0.6057 - val_acc: 0.6820\n",
      "Epoch 55/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.3549 - acc: 0.8333 - val_loss: 0.5976 - val_acc: 0.6600\n",
      "Epoch 56/100\n",
      "26745/26745 [==============================] - 6s 219us/step - loss: 0.3538 - acc: 0.8313 - val_loss: 0.5776 - val_acc: 0.6758\n",
      "Epoch 57/100\n",
      "26745/26745 [==============================] - 6s 227us/step - loss: 0.3524 - acc: 0.8339 - val_loss: 0.5958 - val_acc: 0.6932\n",
      "Epoch 58/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.3477 - acc: 0.8380 - val_loss: 0.6009 - val_acc: 0.6626\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.3447 - acc: 0.8422 - val_loss: 0.5982 - val_acc: 0.6710\n",
      "Epoch 60/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.3431 - acc: 0.8423 - val_loss: 0.6063 - val_acc: 0.6850\n",
      "Epoch 61/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.3422 - acc: 0.8421 - val_loss: 0.6080 - val_acc: 0.6741\n",
      "Epoch 62/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.3356 - acc: 0.8438 - val_loss: 0.6541 - val_acc: 0.6713\n",
      "Epoch 63/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.3339 - acc: 0.8472 - val_loss: 0.5999 - val_acc: 0.6881\n",
      "Epoch 64/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.3339 - acc: 0.8464 - val_loss: 0.6284 - val_acc: 0.6560\n",
      "Epoch 65/100\n",
      "26745/26745 [==============================] - 6s 208us/step - loss: 0.3360 - acc: 0.8444 - val_loss: 0.6966 - val_acc: 0.6407\n",
      "Epoch 66/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3320 - acc: 0.8476 - val_loss: 0.5633 - val_acc: 0.6944\n",
      "Epoch 67/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3299 - acc: 0.8498 - val_loss: 0.6030 - val_acc: 0.6878\n",
      "Epoch 68/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3296 - acc: 0.8494 - val_loss: 0.6140 - val_acc: 0.6812\n",
      "Epoch 69/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3257 - acc: 0.8520 - val_loss: 0.6042 - val_acc: 0.6797\n",
      "Epoch 70/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.3223 - acc: 0.8529 - val_loss: 0.6326 - val_acc: 0.6817\n",
      "Epoch 71/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.3215 - acc: 0.8555 - val_loss: 0.5804 - val_acc: 0.6978\n",
      "Epoch 72/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.3235 - acc: 0.8532 - val_loss: 0.5868 - val_acc: 0.6843\n",
      "Epoch 73/100\n",
      "26745/26745 [==============================] - 6s 209us/step - loss: 0.3237 - acc: 0.8525 - val_loss: 0.5871 - val_acc: 0.6891\n",
      "Epoch 74/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3165 - acc: 0.8573 - val_loss: 0.6776 - val_acc: 0.6616\n",
      "Epoch 75/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3171 - acc: 0.8579 - val_loss: 0.5888 - val_acc: 0.7008\n",
      "Epoch 76/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.3163 - acc: 0.8596 - val_loss: 0.6179 - val_acc: 0.6848\n",
      "Epoch 77/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3145 - acc: 0.8587 - val_loss: 0.5643 - val_acc: 0.7077\n",
      "Epoch 78/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.3122 - acc: 0.8589 - val_loss: 0.6221 - val_acc: 0.6835\n",
      "Epoch 79/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.3114 - acc: 0.8593 - val_loss: 0.6042 - val_acc: 0.7008\n",
      "Epoch 80/100\n",
      "26745/26745 [==============================] - 6s 216us/step - loss: 0.3089 - acc: 0.8616 - val_loss: 0.5851 - val_acc: 0.6916\n",
      "Epoch 81/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3071 - acc: 0.8605 - val_loss: 0.5944 - val_acc: 0.6993\n",
      "Epoch 82/100\n",
      "26745/26745 [==============================] - 6s 213us/step - loss: 0.3087 - acc: 0.8615 - val_loss: 0.5724 - val_acc: 0.7110\n",
      "Epoch 83/100\n",
      "26745/26745 [==============================] - 6s 210us/step - loss: 0.3061 - acc: 0.8638 - val_loss: 0.6019 - val_acc: 0.6916\n",
      "Epoch 84/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.3087 - acc: 0.8629 - val_loss: 0.5958 - val_acc: 0.7074\n",
      "Epoch 85/100\n",
      "26745/26745 [==============================] - 6s 213us/step - loss: 0.3046 - acc: 0.8641 - val_loss: 0.5598 - val_acc: 0.7225\n",
      "Epoch 86/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.3043 - acc: 0.8658 - val_loss: 0.5561 - val_acc: 0.7179\n",
      "Epoch 87/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.3034 - acc: 0.8649 - val_loss: 0.5947 - val_acc: 0.7011\n",
      "Epoch 88/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.2966 - acc: 0.8707 - val_loss: 0.5623 - val_acc: 0.7324\n",
      "Epoch 89/100\n",
      "26745/26745 [==============================] - 6s 212us/step - loss: 0.2975 - acc: 0.8681 - val_loss: 0.5920 - val_acc: 0.6998\n",
      "Epoch 90/100\n",
      "26745/26745 [==============================] - 6s 211us/step - loss: 0.2980 - acc: 0.8676 - val_loss: 0.5711 - val_acc: 0.7209\n",
      "Epoch 91/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.2914 - acc: 0.8701 - val_loss: 0.5770 - val_acc: 0.7230\n",
      "Epoch 92/100\n",
      "26745/26745 [==============================] - 6s 230us/step - loss: 0.2954 - acc: 0.8689 - val_loss: 0.5427 - val_acc: 0.7375\n",
      "Epoch 93/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.2870 - acc: 0.8768 - val_loss: 0.5448 - val_acc: 0.7355\n",
      "Epoch 94/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.2887 - acc: 0.8740 - val_loss: 0.5567 - val_acc: 0.7309\n",
      "Epoch 95/100\n",
      "26745/26745 [==============================] - 6s 218us/step - loss: 0.2897 - acc: 0.8744 - val_loss: 0.5774 - val_acc: 0.7156\n",
      "Epoch 96/100\n",
      "26745/26745 [==============================] - 6s 215us/step - loss: 0.2872 - acc: 0.8744 - val_loss: 0.5836 - val_acc: 0.7123\n",
      "Epoch 97/100\n",
      "26745/26745 [==============================] - 6s 217us/step - loss: 0.2832 - acc: 0.8734 - val_loss: 0.5805 - val_acc: 0.7057\n",
      "Epoch 98/100\n",
      "26745/26745 [==============================] - 6s 214us/step - loss: 0.2866 - acc: 0.8766 - val_loss: 0.6008 - val_acc: 0.7159\n",
      "Epoch 99/100\n",
      " 3500/26745 [==>...........................] - ETA: 4s - loss: 0.2814 - acc: 0.8769"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=100, verbose=1, validation_data=(X_test,y_test), batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
